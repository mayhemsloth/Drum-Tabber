{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is meant to be accessed via Google Colab and will be the main method to train models on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# primary importing code block to utilize the python files\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, ZeroPadding2D, BatchNormalization, MaxPool2D\n",
    "from pydub import AudioSegment   # main class from pydub package used to upload mp3 into Python and then get a NumPy array\n",
    "import IPython.display as ipd    # ability to play audio in Jupyter Notebooks if needed\n",
    "import librosa as lb             # loads the librosa package\n",
    "import librosa.display\n",
    "from src.configs import *\n",
    "from src.utils import MusicAlignedTab, create_FullSet_df, one_hot_encode, collapse_class, clean_labels\n",
    "from src.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mat = MusicAlignedTab('mookies_last_christmas')\n",
    "df = mat.MAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_labels(df)\n",
    "MusicAlignedTab.labels_summary(df)\n",
    "df = collapse_class(df, keep_dynamics = False, keep_bells = False, keep_toms_separate = False, hihat_classes=1, cymbal_classes=1)\n",
    "MusicAlignedTab.labels_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_df = one_hot_encode(df)\n",
    "print(encode_df.columns)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time targets, target_dict = create_targets(S, encode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, val in target_dict.items():\n",
    "    print(f'total windows that {val} are labeled 1 = {np.count_nonzero(targets[idx,:,0])}')\n",
    "print(f'total windows = {targets.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (10,10))\n",
    "ax = fig.add_subplot()\n",
    "plt.imshow(targets[:,:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MusicAlignedTab.labels_summary(encode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.zeros((7, 10, 3), dtype=int)\n",
    "print(targets.shape)\n",
    "targets[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['song slice', 'sample start'])[df.drop(columns = ['song slice', 'sample start']) != '-'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat.random_alignment_checker(['BD', 'SD', 'CC'], 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "librosa.display.specshow(S[:,:,0], sr=44100, x_axis='time', y_axis = 'mel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FullSet Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play(samples, sr=44100):\n",
    "    '''\n",
    "    Helper function just so I can type play(samples) to get the song output\n",
    "    '''\n",
    "    return ipd.Audio(samples, rate = sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FullSet = create_FullSet_df(SONGS_PATH)\n",
    "FullSet_clean = clean_labels(FullSet)\n",
    "MusicAlignedTab.labels_summary(FullSet_clean)\n",
    "FullSet_collapse = collapse_class(FullSet_clean, keep_dynamics = False, keep_bells = False, keep_toms_separate = False, hihat_classes=1, cymbal_classes=1)\n",
    "MusicAlignedTab.labels_summary(FullSet_collapse)\n",
    "FullSet_encoded = one_hot_encode(FullSet_collapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tset = Dataset('train', FullSet_encoded)\n",
    "vset = Dataset('val', FullSet_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "song_df = tset.subset_df.loc[tset.song_list[song_idx]].copy()\n",
    "song = np.vstack(song_df['song slice'].to_numpy()).T   # stacks the song slices back into a single numpy array of shape (channels, samples)\n",
    "mono_song = lb.core.to_mono(song)\n",
    "channels = [mono_song]              # channels is a list of either [mono_song] or [mono, L_song, R_song]\n",
    "if INCLUDE_LR_CHANNELS:             # appending the LR channels to the channels variable\n",
    "    channels.append(song[0,:])\n",
    "    channels.append(song[1,:])\n",
    "aug_channels = tset.augment_audio_cp(channels, tset.aug_comp, sr=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "play(aug_channels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INCLUDE_LR_CHANNELS = False\n",
    "%time spectrogram, target, target_dict = tset.preprocess_song(tset.song_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spectrogram.shape)\n",
    "print(target.shape)\n",
    "print(target_dict)\n",
    "tset.song_list[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vset.subset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.zeros((5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = vset.subset_df.loc['four_years'].drop(columns = ['sample start', 'song slice']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack([labels_df.loc[0].to_numpy() for _ in range(3)], axis = -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.zeros((7, 15,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "save_spec = []\n",
    "save_tar = []\n",
    "for spec, tar in vset:\n",
    "    save_spec.append(spec)\n",
    "    save_tar.append(tar)\n",
    "    print(f'shape of target = {tar.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_spec = save_spec[0]\n",
    "mb_spec = save_spec[1]\n",
    "fy_tar = save_tar[0]\n",
    "mb_tar = save_tar[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpysave_fp = 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Experimental/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(numpysave_fp + 'fy_spec', fy_spec)\n",
    "np.save(numpysave_fp + 'fy_tar', fy_tar)\n",
    "np.save(numpysave_fp + 'm_spec', mb_spec)\n",
    "np.save(numpysave_fp + 'mb_tar', mb_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(numpysave_fp + 'zip_uncomp', fy_spec, fy_tar, mb_spec, mb_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(numpysave_fp + 'zip_comp', fy_spec, fy_tar, mb_spec, mb_tar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_spec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_tar.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_chan = fy_spec[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_spectrogram(spectrogram, pre_context, post_context):\n",
    "    '''\n",
    "    Expands a 2D spectrogram into slices of the correct shape to be input into the model\n",
    "    \n",
    "    Args:\n",
    "        spectrogram [np.array]:\n",
    "        pre_context [int]:\n",
    "        post_context [int]:\n",
    "    \n",
    "    Returns:\n",
    "        np.array: \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    n_features, n_windows = spectrogram.shape\n",
    "    \n",
    "    input_width = 1 + pre_context + post_context\n",
    "    min_value = np.min(spectrogram)\n",
    "    \n",
    "    expanded_spectrogram = np.full(shape = (n_windows, n_features, input_width), fill_value = min_value)# assign into this np.array\n",
    "    \n",
    "    for idx in range(n_windows):\n",
    "        if idx - pre_context < 0:    # in a window where you would slice before the beginning\n",
    "            start = pre_context-idx\n",
    "            expanded_spectrogram[idx, :,start:] = spectrogram[:, 0:idx+post_context+1 ]\n",
    "        elif idx + post_context+1 > n_windows: # in a window where you would slice past the end\n",
    "            end = post_context+1 - (n_windows - idx)\n",
    "            expanded_spectrogram[idx, :, :input_width-end] = spectrogram[:, idx-pre_context: n_windows ]\n",
    "        else:    # in a \"normal\" middle window where you slice into the spectrogram normally\n",
    "            expanded_spectrogram[idx, :,:] = spectrogram[:, idx-pre_context : idx+post_context+1]\n",
    "    \n",
    "    return expanded_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "exp_spec = expand_spectrogram(one_chan, 5,5)\n",
    "exp_spec[10000,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_spec[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "one_chan.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing of the train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subdirs = ['C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\ancient_tombs', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\best_of_me', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\boulevard_of_broken_dreams', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\cant_be_saved', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\face_down', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\family_tradition', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\fireworks_at_dawn', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\forever_at_last', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\four_years', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\garden_state', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\gunpowder', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\hair_of_the_dog', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\lungs_like_gallows', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\misery_business', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\mookies_last_christmas', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\planning_a_prison_break', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\rollercoaster', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\sow', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\sugar_were_going_down', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\surprise_surprise', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\thats_what_you_get', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\the_dark', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\the_kill', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\the_rapture', 'C:/Users/Thomas/Python Projects/Drum-Tabber-Support-Data/Songs\\\\wolves_at_the_door']\n",
      "list_of_songs = ['ancient_tombs', 'best_of_me', 'boulevard_of_broken_dreams', 'cant_be_saved', 'face_down', 'family_tradition', 'fireworks_at_dawn', 'forever_at_last', 'four_years', 'garden_state', 'gunpowder', 'hair_of_the_dog', 'lungs_like_gallows', 'misery_business', 'mookies_last_christmas', 'planning_a_prison_break', 'rollercoaster', 'sow', 'sugar_were_going_down', 'surprise_surprise', 'thats_what_you_get', 'the_dark', 'the_kill', 'the_rapture', 'wolves_at_the_door']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tab length = 2882     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 2882     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (3392, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (2882,)\n",
      "len(sample_start_list) = 2882\n",
      "tab length = 1628     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1628     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (6182, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1628,)\n",
      "len(sample_start_list) = 1628\n",
      "tab length = 1440     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1440     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (7922, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1440,)\n",
      "len(sample_start_list) = 1440\n",
      "tab length = 2110     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 2110     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (3891, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (2110,)\n",
      "len(sample_start_list) = 2110\n",
      "tab length = 2310     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 2310     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (3556, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (2310,)\n",
      "len(sample_start_list) = 2310\n",
      "tab length = 2448     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 2448     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (3595, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (2448,)\n",
      "len(sample_start_list) = 2448\n",
      "tab length = 608     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 608     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (8067, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (608,)\n",
      "len(sample_start_list) = 608\n",
      "tab length = 1787     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1787     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (5167, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1787,)\n",
      "len(sample_start_list) = 1787\n",
      "tab length = 2134     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 2134     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (5167, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (2134,)\n",
      "len(sample_start_list) = 2134\n",
      "tab length = 2658     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 2658     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (3481, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (2658,)\n",
      "len(sample_start_list) = 2658\n",
      "tab length = 3150     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 3150     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (4009, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (3150,)\n",
      "len(sample_start_list) = 3150\n",
      "tab length = 1904     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1904     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (5011, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1904,)\n",
      "len(sample_start_list) = 1904\n",
      "tab length = 1972     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1972     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (4469, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1972,)\n",
      "len(sample_start_list) = 1972\n",
      "tab length = 2400     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 2400     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (3824, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (2400,)\n",
      "len(sample_start_list) = 2400\n",
      "tab length = 1936     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1936     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (3445, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1936,)\n",
      "len(sample_start_list) = 1936\n",
      "tab length = 3792     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 3792     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (3634, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (3792,)\n",
      "len(sample_start_list) = 3792\n",
      "tab length = 1826     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1826     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (6125, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1826, 6125, 2)\n",
      "len(sample_start_list) = 1826\n",
      "tab length = 1478     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1478     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (5752, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1478,)\n",
      "len(sample_start_list) = 1478\n",
      "tab length = 1122     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1122     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (8166, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1122,)\n",
      "len(sample_start_list) = 1122\n",
      "tab length = 1872     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1872     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (5250, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1872, 5250, 2)\n",
      "len(sample_start_list) = 1872\n",
      "tab length = 1848     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1848     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (5049, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1848,)\n",
      "len(sample_start_list) = 1848\n",
      "tab length = 2512     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 2512     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (4134, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (2512,)\n",
      "len(sample_start_list) = 2512\n",
      "tab length = 1284     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1284     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (7229, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1284,)\n",
      "len(sample_start_list) = 1284\n",
      "tab length = 832     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 832     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (5334, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (832,)\n",
      "len(sample_start_list) = 832\n",
      "tab length = 1984     datatype: <class 'int'>\n",
      "len(song_slices_tab_indexed) = 1984     datatype of object: <class 'list'>\n",
      "song_slices_tab_indexed[0].shape = (4594, 2)     datatype of [0]: <class 'numpy.ndarray'>\n",
      "np.array(song_slices_tab_indexed).shape = (1984,)\n",
      "len(sample_start_list) = 1984\n",
      "...Concatenating all music-aligned dataframes\n",
      "...Replacing NaNs with - for output\n",
      "---dataframe.describe() without blank_chars---\n",
      "           tk     BD    SD    HH    RD    CC    C2   LT   MT   HT  CH   C3  SC\n",
      "count   49917  11829  7624  5388  1718  3279  2334  994  391  298  97  302  26\n",
      "unique      9      3     8     9     5     4     4    5    4    4   3    3   2\n",
      "top         +      o     o     x     x     X     X    o    o    o   X    X   X\n",
      "freq    12461  11356  6527  2905  1090  2016  1891  888  315  249  81  264  20\n",
      "\n",
      "---Unique values and frequencies by column name---\n",
      "        +      e      a     1     2     3     4   t   s\n",
      "tk  12461  12459  12446  3206  3202  3199  2867  47  30\n",
      "\n",
      "        -      o    O   d\n",
      "BD  38088  11356  430  43\n",
      "\n",
      "        -     o    g    O    f   d   r   x  0\n",
      "SD  42293  6527  527  271  136  75  73  14  1\n",
      "\n",
      "        -     x     X    o   O   s   g  S  w  d\n",
      "HH  44529  2905  2186  195  35  32  26  5  2  2\n",
      "\n",
      "        -     x    X    b   g   f\n",
      "RD  48199  1090  476  113  25  14\n",
      "\n",
      "        -     X     x  b  #\n",
      "CC  46638  2016  1252  7  4\n",
      "\n",
      "        -     X    x  #  b\n",
      "C2  47583  1891  439  3  1\n",
      "\n",
      "        -    o   O   D   d   f\n",
      "LT  48923  888  47  31  16  12\n",
      "\n",
      "        -    o   O   d  f\n",
      "MT  49526  315  57  10  9\n",
      "\n",
      "        -    o   O  f  d\n",
      "HT  49619  249  36  8  5\n",
      "\n",
      "        -   X   x  g\n",
      "CH  49820  81  14  2\n",
      "\n",
      "        -    X   x   #\n",
      "C3  49615  264  26  12\n",
      "\n",
      "        -   X  b\n",
      "SC  49891  20  6\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---dataframe.describe() without blank_chars---\n",
      "           tk     BD    SD    HH    RD    CC    C2   LT   MT   HT  CH   C3  SC\n",
      "count   49917  11829  7551  5351  1718  3275  2331  994  391  298  97  290  26\n",
      "unique      9      2     3     4     4     3     3    2    2    2   3    2   2\n",
      "top         +      o     o     x     x     X     X    o    o    o   X    X   X\n",
      "freq    12461  11399  6752  2907  1104  2016  1891  916  334  262  81  264  20\n",
      "\n",
      "---Unique values and frequencies by column name---\n",
      "        +      e      a     1     2     3     4   t   s\n",
      "tk  12461  12459  12446  3206  3202  3199  2867  47  30\n",
      "\n",
      "        -      o    O\n",
      "BD  38088  11399  430\n",
      "\n",
      "        -     o    g    O\n",
      "SD  42366  6752  527  272\n",
      "\n",
      "        -     x     X    o   g\n",
      "HH  44566  2907  2188  230  26\n",
      "\n",
      "        -     x    X    b   g\n",
      "RD  48199  1104  476  113  25\n",
      "\n",
      "        -     X     x  b\n",
      "CC  46642  2016  1252  7\n",
      "\n",
      "        -     X    x  b\n",
      "C2  47586  1891  439  1\n",
      "\n",
      "        -    o   O\n",
      "LT  48923  916  78\n",
      "\n",
      "        -    o   O\n",
      "MT  49526  334  57\n",
      "\n",
      "        -    o   O\n",
      "HT  49619  262  36\n",
      "\n",
      "        -   X   x  g\n",
      "CH  49820  81  14  2\n",
      "\n",
      "        -    X   x\n",
      "C3  49627  264  26\n",
      "\n",
      "        -   X  b\n",
      "SC  49891  20  6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\missing.py:49: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask = arr == x\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---dataframe.describe() without blank_chars---\n",
      "           tk     BD    SD    HH    at    ac\n",
      "count   12474  11829  7024  2907  1540  9801\n",
      "unique      2      1     1     1     1     1\n",
      "top         c      o     o     x     o     x\n",
      "freq     9268  11829  7024  2907  1540  9801\n",
      "\n",
      "---Unique values and frequencies by column name---\n",
      "        -     c     C\n",
      "tk  37443  9268  3206\n",
      "\n",
      "        -      o\n",
      "BD  38088  11829\n",
      "\n",
      "        -     o\n",
      "SD  42893  7024\n",
      "\n",
      "        -     x\n",
      "HH  47010  2907\n",
      "\n",
      "        -     o\n",
      "at  48377  1540\n",
      "\n",
      "        -     x\n",
      "ac  40116  9801\n",
      "\n",
      "one_hot_encode: col_list before encoding = ['tk', 'BD', 'SD', 'HH', 'at', 'ac']\n",
      "one_hot_encode: col_list after encoding = ['song slice', 'sample start', 'tk_beat', 'tk_downbeat', 'BD_o', 'SD_o', 'HH_x', 'at_o', 'ac_x']\n",
      "train.py main(): FullSet_encoded created!\n",
      "train.py main(): drum_tabber model created!\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 50, 31, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 50, 31, 32)        288       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 50, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 50, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 50, 31, 32)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 50, 31, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 50, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 50, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 17, 11, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 11, 64)        18432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 17, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 17, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 17, 11, 64)        36864     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 17, 11, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 17, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 17, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 6, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               393472    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 528,679\n",
      "Trainable params: 527,271\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "None\n",
      "Starting Epoch 0/4\n",
      "Dataset class __next__: preprocessing ancient_tombs\n",
      "WARNING:tensorflow:Layer conv2d is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch: 0 Song  1/23, lr:0.000004, song_loss:0.977119\n",
      "Dataset class __next__: preprocessing best_of_me\n",
      "Epoch: 0 Song  2/23, lr:0.000009, song_loss:0.967120\n",
      "Dataset class __next__: preprocessing boulevard_of_broken_dreams\n",
      "Epoch: 0 Song  3/23, lr:0.000013, song_loss:0.970717\n",
      "Dataset class __next__: preprocessing cant_be_saved\n",
      "Epoch: 0 Song  4/23, lr:0.000017, song_loss:0.960991\n",
      "Dataset class __next__: preprocessing face_down\n",
      "Epoch: 0 Song  5/23, lr:0.000022, song_loss:0.955531\n",
      "Dataset class __next__: preprocessing family_tradition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Song  6/23, lr:0.000026, song_loss:0.951794\n",
      "Dataset class __next__: preprocessing fireworks_at_dawn\n",
      "Epoch: 0 Song  7/23, lr:0.000030, song_loss:0.935100\n",
      "Dataset class __next__: preprocessing forever_at_last\n",
      "Epoch: 0 Song  8/23, lr:0.000035, song_loss:0.946203\n",
      "Dataset class __next__: preprocessing garden_state\n",
      "Epoch: 0 Song  9/23, lr:0.000039, song_loss:0.931625\n",
      "Dataset class __next__: preprocessing gunpowder\n",
      "Epoch: 0 Song 10/23, lr:0.000043, song_loss:0.851899\n",
      "Dataset class __next__: preprocessing hair_of_the_dog\n",
      "Epoch: 0 Song 11/23, lr:0.000048, song_loss:0.802483\n",
      "Dataset class __next__: preprocessing lungs_like_gallows\n",
      "Epoch: 0 Song 12/23, lr:0.000052, song_loss:0.785794\n",
      "Dataset class __next__: preprocessing mookies_last_christmas\n",
      "Epoch: 0 Song 13/23, lr:0.000057, song_loss:0.795409\n",
      "Dataset class __next__: preprocessing planning_a_prison_break\n",
      "Epoch: 0 Song 14/23, lr:0.000061, song_loss:0.772324\n",
      "Dataset class __next__: preprocessing rollercoaster\n",
      "Epoch: 0 Song 15/23, lr:0.000065, song_loss:0.753070\n",
      "Dataset class __next__: preprocessing sow\n",
      "Epoch: 0 Song 16/23, lr:0.000070, song_loss:0.765202\n",
      "Dataset class __next__: preprocessing sugar_were_going_down\n",
      "Epoch: 0 Song 17/23, lr:0.000074, song_loss:0.738973\n",
      "Dataset class __next__: preprocessing surprise_surprise\n",
      "Epoch: 0 Song 18/23, lr:0.000078, song_loss:0.754519\n",
      "Dataset class __next__: preprocessing thats_what_you_get\n",
      "Epoch: 0 Song 19/23, lr:0.000083, song_loss:0.732743\n",
      "Dataset class __next__: preprocessing the_dark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Song 20/23, lr:0.000087, song_loss:0.728565\n",
      "Dataset class __next__: preprocessing the_kill\n",
      "Epoch: 0 Song 21/23, lr:0.000091, song_loss:0.728903\n",
      "Dataset class __next__: preprocessing the_rapture\n",
      "Epoch: 0 Song 22/23, lr:0.000096, song_loss:0.721049\n",
      "Dataset class __next__: preprocessing wolves_at_the_door\n",
      "Epoch: 0 Song  0/23, lr:0.000100, song_loss:0.714724\n",
      "Dataset class __next__: preprocessing four_years\n",
      "Dataset class __next__: preprocessing misery_business\n",
      "\n",
      "\n",
      "Epoch:  0 val_loss:0.763304 \n",
      "\n",
      "\n",
      "Starting Epoch 1/4\n",
      "Dataset class __next__: preprocessing lungs_like_gallows\n",
      "Epoch: 1 Song  1/23, lr:0.000100, song_loss:0.708597\n",
      "Dataset class __next__: preprocessing the_kill\n",
      "Epoch: 1 Song  2/23, lr:0.000100, song_loss:0.707649\n",
      "Dataset class __next__: preprocessing the_rapture\n",
      "Epoch: 1 Song  3/23, lr:0.000100, song_loss:0.708833\n",
      "Dataset class __next__: preprocessing face_down\n",
      "Epoch: 1 Song  4/23, lr:0.000099, song_loss:0.704507\n",
      "Dataset class __next__: preprocessing family_tradition\n",
      "Epoch: 1 Song  5/23, lr:0.000099, song_loss:0.702652\n",
      "Dataset class __next__: preprocessing gunpowder\n",
      "Epoch: 1 Song  6/23, lr:0.000098, song_loss:0.701319\n",
      "Dataset class __next__: preprocessing ancient_tombs\n",
      "Epoch: 1 Song  7/23, lr:0.000098, song_loss:0.697882\n",
      "Dataset class __next__: preprocessing thats_what_you_get\n",
      "Epoch: 1 Song  8/23, lr:0.000097, song_loss:0.696342\n",
      "Dataset class __next__: preprocessing hair_of_the_dog\n",
      "Epoch: 1 Song  9/23, lr:0.000096, song_loss:0.695172\n",
      "Dataset class __next__: preprocessing fireworks_at_dawn\n",
      "Epoch: 1 Song 10/23, lr:0.000095, song_loss:0.695002\n",
      "Dataset class __next__: preprocessing garden_state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Song 11/23, lr:0.000094, song_loss:0.694508\n",
      "Dataset class __next__: preprocessing planning_a_prison_break\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Song 12/23, lr:0.000093, song_loss:0.694306\n",
      "Dataset class __next__: preprocessing rollercoaster\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Song 13/23, lr:0.000092, song_loss:0.694149\n",
      "Dataset class __next__: preprocessing cant_be_saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Song 14/23, lr:0.000090, song_loss:0.693888\n",
      "Dataset class __next__: preprocessing best_of_me\n",
      "Epoch: 1 Song 15/23, lr:0.000089, song_loss:0.693793\n",
      "Dataset class __next__: preprocessing boulevard_of_broken_dreams\n",
      "Epoch: 1 Song 16/23, lr:0.000087, song_loss:0.693957\n",
      "Dataset class __next__: preprocessing mookies_last_christmas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Song 17/23, lr:0.000086, song_loss:0.693621\n",
      "Dataset class __next__: preprocessing wolves_at_the_door\n",
      "Epoch: 1 Song 18/23, lr:0.000084, song_loss:0.693597\n",
      "Dataset class __next__: preprocessing forever_at_last\n",
      "Epoch: 1 Song 19/23, lr:0.000083, song_loss:0.693645\n",
      "Dataset class __next__: preprocessing sugar_were_going_down\n",
      "Epoch: 1 Song 20/23, lr:0.000081, song_loss:0.693459\n",
      "Dataset class __next__: preprocessing surprise_surprise\n",
      "Epoch: 1 Song 21/23, lr:0.000079, song_loss:0.693453\n",
      "Dataset class __next__: preprocessing sow\n",
      "Epoch: 1 Song 22/23, lr:0.000077, song_loss:0.693508\n",
      "Dataset class __next__: preprocessing the_dark\n",
      "Epoch: 1 Song  0/23, lr:0.000075, song_loss:0.693361\n",
      "Dataset class __next__: preprocessing four_years\n",
      "Dataset class __next__: preprocessing misery_business\n",
      "\n",
      "\n",
      "Epoch:  1 val_loss:0.718876 \n",
      "\n",
      "\n",
      "Starting Epoch 2/4\n",
      "Dataset class __next__: preprocessing the_rapture\n",
      "Epoch: 2 Song  1/23, lr:0.000073, song_loss:0.693345\n",
      "Dataset class __next__: preprocessing mookies_last_christmas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Song  2/23, lr:0.000071, song_loss:0.693328\n",
      "Dataset class __next__: preprocessing garden_state\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Song  3/23, lr:0.000069, song_loss:0.693312\n",
      "Dataset class __next__: preprocessing fireworks_at_dawn\n",
      "Epoch: 2 Song  4/23, lr:0.000067, song_loss:0.693304\n",
      "Dataset class __next__: preprocessing gunpowder\n",
      "Epoch: 2 Song  5/23, lr:0.000065, song_loss:0.693294\n",
      "Dataset class __next__: preprocessing the_dark\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Song  6/23, lr:0.000063, song_loss:0.693284\n",
      "Dataset class __next__: preprocessing sugar_were_going_down\n",
      "Epoch: 2 Song  7/23, lr:0.000061, song_loss:0.693264\n",
      "Dataset class __next__: preprocessing lungs_like_gallows\n",
      "Epoch: 2 Song  8/23, lr:0.000058, song_loss:0.693255\n",
      "Dataset class __next__: preprocessing surprise_surprise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Song  9/23, lr:0.000056, song_loss:0.693262\n",
      "Dataset class __next__: preprocessing face_down\n",
      "Epoch: 2 Song 10/23, lr:0.000054, song_loss:0.693241\n",
      "Dataset class __next__: preprocessing planning_a_prison_break\n",
      "Epoch: 2 Song 11/23, lr:0.000052, song_loss:0.693245\n",
      "Dataset class __next__: preprocessing forever_at_last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Song 12/23, lr:0.000049, song_loss:0.693229\n",
      "Dataset class __next__: preprocessing ancient_tombs\n",
      "Epoch: 2 Song 13/23, lr:0.000047, song_loss:0.693223\n",
      "Dataset class __next__: preprocessing best_of_me\n",
      "Epoch: 2 Song 14/23, lr:0.000045, song_loss:0.693213\n",
      "Dataset class __next__: preprocessing rollercoaster\n",
      "Epoch: 2 Song 15/23, lr:0.000043, song_loss:0.693209\n",
      "Dataset class __next__: preprocessing sow\n",
      "Epoch: 2 Song 16/23, lr:0.000040, song_loss:0.693242\n",
      "Dataset class __next__: preprocessing cant_be_saved\n",
      "Epoch: 2 Song 17/23, lr:0.000038, song_loss:0.693200\n",
      "Dataset class __next__: preprocessing thats_what_you_get\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Song 18/23, lr:0.000036, song_loss:0.693203\n",
      "Dataset class __next__: preprocessing wolves_at_the_door\n",
      "Epoch: 2 Song 19/23, lr:0.000034, song_loss:0.693193\n",
      "Dataset class __next__: preprocessing the_kill\n",
      "Epoch: 2 Song 20/23, lr:0.000032, song_loss:0.693198\n",
      "Dataset class __next__: preprocessing boulevard_of_broken_dreams\n",
      "Epoch: 2 Song 21/23, lr:0.000030, song_loss:0.693193\n",
      "Dataset class __next__: preprocessing family_tradition\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:161: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn('PySoundFile failed. Trying audioread instead.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Song 22/23, lr:0.000028, song_loss:0.693193\n",
      "Dataset class __next__: preprocessing hair_of_the_dog\n",
      "Epoch: 2 Song  0/23, lr:0.000026, song_loss:0.693193\n",
      "Dataset class __next__: preprocessing four_years\n",
      "Dataset class __next__: preprocessing misery_business\n",
      "\n",
      "\n",
      "Epoch:  2 val_loss:0.738158 \n",
      "\n",
      "\n",
      "Starting Epoch 3/4\n",
      "Dataset class __next__: preprocessing sow\n",
      "Epoch: 3 Song  1/23, lr:0.000024, song_loss:0.693193\n",
      "Dataset class __next__: preprocessing cant_be_saved\n",
      "Epoch: 3 Song  2/23, lr:0.000022, song_loss:0.693181\n",
      "Dataset class __next__: preprocessing hair_of_the_dog\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Python Projects\\Drum-Tabber\\train.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    342\u001b[0m             \u001b[0mdrum_tabber\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_model_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mTRAIN_SAVE_CHECKPOINT_MAX_BEST\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtotal_val\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_val_songs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mbest_val_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m             \u001b[0msave_model_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_CHECKPOINTS_FOLDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMODEL_TYPE\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mconfigs_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'month_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m             \u001b[0mbest_val_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_val\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn_val_songs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mdrum_tabber\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msave_model_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python Projects\\Drum-Tabber\\train.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Starting Epoch {epoch+1}/{TRAIN_EPOCHS}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mspectrogram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# outputs a full song's spectrogram and target, over the entire dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m             \u001b[1;31m# do a train step with the current spectrogram and target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[0mloss_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_song_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mcurrent_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Python Projects\\Drum-Tabber\\train.py\u001b[0m in \u001b[0;36mtrain_song_step\u001b[1;34m(spectrogram, target)\u001b[0m\n\u001b[0;32m    234\u001b[0m                     \u001b[0mtotal_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# gets the average of all the classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m                     \u001b[1;31m# apply gradients to update the model, the backward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m                     \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrum_tabber\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrum_tabber\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m                 \u001b[0mchannel_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1014\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_zeros\u001b[1;34m(shape, dtype)\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_zeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m   \u001b[1;34m\"\"\"Helper to return (possibly cached) zero tensors in eager mode.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m   if (dtype == dtypes.variant\n\u001b[0m\u001b[0;32m    629\u001b[0m       \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m       or dtype == dtypes.resource):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "int1 = 0\n",
    "int2 = 100\n",
    "Song = 1\n",
    "lr= 0.00023453\n",
    "song_l = 234.4566"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/100 Song  1, lr:0.000235, song_loss:  234.46\n"
     ]
    }
   ],
   "source": [
    "print('Epoch: {:2}/{} Song{:3}, lr:{:.6f}, song_loss:{:8.2f}'.format(int1, int2, Song, lr, song_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
